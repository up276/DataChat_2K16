{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity method #2\n",
    "\n",
    "The objective of this notebook is to build a way to measure similarities between intents. \n",
    "\n",
    "A first method was previously build and was implementing continuous bags of words (CBOW), which consisted in simply embedding each question as the average of the embeddings of its words (possible modulations of this method consisted in 1. Taking the weighted average with weights being the inverse document frequency of the words, where the idf are computed on a relevant train set, and 2. Only summing the embedding of some words of interests, like nouns, which usually convey most of what people are asking for when asking a question). Once all questions are embedded, we compare the similarity between two questions using a similarity measure (usually cosine similarity).\n",
    "\n",
    "In this notebook, we try a second method. Rather than summing over all the words of a question and the measuring the similarity with another question, we do as follow:\n",
    "1. Filter both questions using POS tagging (keeping only nouns for instance)\n",
    "2. For each filtered word of question 1, measure similarity with each filtered word of question 2 and keep only the highest similarity measure (intuition is, 2 questions would be similar if they ask for the same \"objects\" with same relationships between those, like 'average', 'number', 'user', 'march'). \n",
    "3. Optional step is to apply a non linearity to penalize lower similarities and give more weight to higher similarities (step detailed in the notebook).\n",
    "4. Consider as similarity score between the two questions the sum of the previously computed pairwise similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import nltk\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load any words embedding\n",
    "# Here we use word2vec Google pretrained model\n",
    "# The link to download those embeddings can be found on this page :\n",
    "# https://github.com/mmihaltz/word2vec-GoogleNews-vectors  (download .gz file in the README)\n",
    "\n",
    "path = './model/GoogleNews-vectors-negative300.bin'\n",
    "model = gensim.models.Word2Vec.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59324205934254348"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('customers','users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introduction\n",
    "\n",
    "The Objective here is just to show separately which core function we'll use to build our similarity module, and what each function does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech (POS)\n",
    "\n",
    "Here, we just quickly show how POS functions work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('many', 'JJ'), ('users', 'NNS'), ('base', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# POS to keep\n",
    "keep_pos = ['NN', 'NNS', 'VB','JJ']\n",
    "\n",
    "# POS tags meaing available at :\n",
    "# https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "# FYI, available POS tags :\n",
    "['PRP$','VBG','VBD','VBN','VBP','WDT','JJ','WP','VBZ','DT','RP','NN','FW','POS',\n",
    "'TO','LS','RB','NNS','NNP','VB','WRB','CC','PDT','RBS','RBR','CD','PRP','EX','IN',\n",
    "'WP$','MD','NNPS','JJS','JJR','SYM','UH']\n",
    "\n",
    "# Question\n",
    "q = 'how many users are in the base'\n",
    "q_tokens = nltk.word_tokenize(q)\n",
    "q_tagged = nltk.pos_tag(q_tokens)\n",
    "q_tagged_filtered = [q_tagged[i] for i in range(len(q_tagged)) if q_tagged[i][1] in keep_pos]\n",
    "\n",
    "print q_tagged_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking singular forms of nouns is important since similarity(A,A') > similarity(As,A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.742383054369\n"
     ]
    }
   ],
   "source": [
    "print model.similarity('car','car')\n",
    "print model.similarity('cars','car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['many', 'user', 'base']\n"
     ]
    }
   ],
   "source": [
    "p = inflect.engine()\n",
    "\n",
    "q_singular = []\n",
    "for pos in q_tagged_filtered:\n",
    "    if pos[1] != 'NNS':\n",
    "        q_singular.append(pos[0]) \n",
    "    elif pos[1] == 'NNS':\n",
    "        q_singular.append(p.singular_noun(pos[0]))\n",
    "\n",
    "print q_singular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise similarities non linear transformation\n",
    "\n",
    "Reason for doing this comes from experimentation observations : usually, semtenticly speaking different words will still have a non-zero similarity (usually < .5 ) wich has a non-negligeable weight when summing over all pairwise similarities (even more if we multiply by the words idf). Hence, we would like to push down those similarities towards 0. Similarly, different but synonyms word will not have 1 similarity (but usually similarities > .5), so we might want to push up those similarities towards 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.554684003043\n",
      "0.107564718592\n"
     ]
    }
   ],
   "source": [
    "# pairwise similarity of similar words is not that far from pairwise similarity of non simmilar words\n",
    "print model.similarity('user','customer')\n",
    "print model.similarity('user','city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25a662b10>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111624c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Most natural non linearity shape we could think about is a sigmoid-like function transposed to [0, 1] --> [0, 1]\n",
    "m = 30\n",
    "x_values = [0.01*x for x in range(101)]\n",
    "y_values = [1/(1+ np.exp(-m*(x-0.5))) for x in x_values]\n",
    "plt.plot(x_values,y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25a8b3a50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZE8ppAXEcljCnkRkTymkBcRyWP/HxDURwwtj1zTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105aa1e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Other non linearities we can thing of (but is not giving results in practice)\n",
    "k = 0.5\n",
    "x_values = [0.01*x for x in range(101)]\n",
    "y_values = [k*x/(k-x+1) for x in x_values]\n",
    "plt.plot(x_values,y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_linear(x, non_linearity='none'):\n",
    "    '''\n",
    "    add a non linearity such as it penalizes values close to 0 (push them even more towards 0)\n",
    "    'exponential' and 'sigmoid' only refer to the shape of the non linearities, but the functions\n",
    "    are adapted to fit on [0,1] --> [0,1]\n",
    "    '''\n",
    "    if non_linearity=='none':\n",
    "        y = x\n",
    "    if non_linearity=='exponential':\n",
    "        k = 0.5\n",
    "        y = k*x/(k-x+1)\n",
    "    if non_linearity=='sigmoid':\n",
    "        m = 20\n",
    "        y = 1/(1+ np.exp(-m*(x-0.5)))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.554684003043\n",
      "0.749074067436\n",
      "0.107564718592\n",
      "0.000390104537917\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid like non linearity enhances the similarities differences \n",
    "print model.similarity('user','customer')\n",
    "print non_linear(model.similarity('user','customer'), non_linearity='sigmoid')\n",
    "print model.similarity('user','city')\n",
    "print non_linear(model.similarity('user','city'), non_linearity='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity #2 code\n",
    "\n",
    "Here we just provide the code implementation of our similarity method #2 explained at the top.\n",
    "The last cell can be used to play around and make comparisons between 2 user questions and 1 hardcoded question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_pos = ['NN', 'NNS', 'VB', 'JJ']\n",
    "\n",
    "def filter_pos(question):\n",
    "    '''\n",
    "    From a sentence, return list of tuples [(word, POS)] if POS in self.keep_pos (by default : noun(s))\n",
    "    '''\n",
    "    question_tokens = nltk.word_tokenize(question)\n",
    "    question_tagged = nltk.pos_tag(question_tokens)\n",
    "    question_tagged_pos = [question_tagged[i] \n",
    "                            for i in range(len(question_tagged)) \n",
    "                            if question_tagged[i][1] \n",
    "                            in keep_pos]\n",
    "    return question_tagged_pos\n",
    "\n",
    "def plural_to_singular(tagged_pos):\n",
    "    '''\n",
    "    Putting all nouns to singular form (because similarity(A,A') > similarity(A,As'))\n",
    "    '''\n",
    "    p = inflect.engine()\n",
    "    q_singular = []\n",
    "    for pos in tagged_pos:\n",
    "        if pos[1] != 'NNS':\n",
    "            q_singular.append(pos[0]) \n",
    "        else:\n",
    "            q_singular.append(p.singular_noun(pos[0]))\n",
    "    return q_singular\n",
    "\n",
    "\n",
    "def find_sim(question_nouns_1, question_nouns_2, non_linearity='none'):\n",
    "    max_len = max(len(question_nouns_1), len(question_nouns_2))\n",
    "    if len(question_nouns_1) == max_len:\n",
    "        seq1, seq2 = question_nouns_1, question_nouns_2\n",
    "    else:\n",
    "        seq1, seq2 = question_nouns_2, question_nouns_1\n",
    "\n",
    "    similarity = {}\n",
    "    for word1 in seq1:\n",
    "        similarities = []\n",
    "        for word2 in seq2:\n",
    "            # try except in case word not in model vocabulary\n",
    "            try:\n",
    "                similarities.append(model.similarity(word1, word2))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            sim_max = max(similarities)\n",
    "            word2_sim_max = seq2[similarities.index(sim_max)]\n",
    "            # apply non linearity\n",
    "            similarity[(word1, word2_sim_max)] = non_linear(sim_max, non_linearity)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        print 'max pairwise similarity: ', word1, word2_sim_max, similarity[(word1, word2_sim_max)]\n",
    "\n",
    "    similarity_score = 0\n",
    "    if len(similarity.values()) > 0 :\n",
    "        similarity_score = sum(similarity.values())/len(similarity.values())\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "\n",
    "\n",
    "def find_similarity(question1, question2, non_linearity='none'):\n",
    "    question_tagged_nouns_1 = filter_pos(question1)\n",
    "    question_tagged_nouns_2 = filter_pos(question2)\n",
    "    question_nouns_1 = plural_to_singular(question_tagged_nouns_1)\n",
    "    question_nouns_2 = plural_to_singular(question_tagged_nouns_2)\n",
    "    similarity_score = find_sim(question_nouns_1, question_nouns_2, non_linearity)\n",
    "    print 'sentence similarity score: '\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With non_linearity=none \n",
      "\n",
      "max pairwise similarity:  many number 0.495196614879\n",
      "max pairwise similarity:  vehicle car 0.782109646008\n",
      "max pairwise similarity:  database database 1.0\n",
      "sentence similarity score: \n",
      "0.759102086962\n",
      " \n",
      "max pairwise similarity:  many many 1.0\n",
      "max pairwise similarity:  vehicle user 0.179300899246\n",
      "max pairwise similarity:  database user 0.304389234559\n",
      "sentence similarity score: \n",
      "0.494563377935\n",
      "\n",
      "With non_linearity=sigmoid \n",
      "\n",
      "max pairwise similarity:  many number 0.476001528389\n",
      "max pairwise similarity:  vehicle car 0.996467437451\n",
      "max pairwise similarity:  database database 0.999954602131\n",
      "sentence similarity score: \n",
      "0.824141189324\n",
      " \n",
      "max pairwise similarity:  many many 0.999954602131\n",
      "max pairwise similarity:  vehicle user 0.00163580676637\n",
      "max pairwise similarity:  database user 0.0196041467584\n",
      "sentence similarity score: \n",
      "0.340398185219\n"
     ]
    }
   ],
   "source": [
    "sent1 = 'how many vehicles do i have in my database'\n",
    "sent2 = 'what is the number of cars in the database'\n",
    "sent3 = 'how many users are in the base \\?'\n",
    "\n",
    "print 'With non_linearity=none \\n'\n",
    "print find_similarity(sent1, sent2, non_linearity='none')\n",
    "print ' ' \n",
    "print find_similarity(sent1, sent3, non_linearity='none')\n",
    "\n",
    "print ''\n",
    "\n",
    "print 'With non_linearity=sigmoid \\n'\n",
    "print find_similarity(sent1, sent2, non_linearity='sigmoid')\n",
    "print ' ' \n",
    "print find_similarity(sent1, sent3, non_linearity='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Once tested on our test set, this method did not demonstrated better results than Similarity method # 1 (slightly less good results indeed). Nevertheless, it's flexibility may allow to find many ways to improve it. Adding a sigmoid like non linearity was one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : For intent detections, it seems that there are some families of words for which it does not seem to work very well: for instance for months, names, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0127895358008\n",
      "0.689945336356\n"
     ]
    }
   ],
   "source": [
    "print model.similarity('may', 'april')\n",
    "print model.similarity('november', 'december')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12254906958201985"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('mike', 'peter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00972544,  0.01378946,  0.00932016,  0.02029282,  0.01833201,\n",
       "        0.06138048,  0.05600813,  0.01979298,  0.01543204,  0.0471283 ,\n",
       "        0.04837809,  0.01248718,  0.00981319,  0.01436945,  0.01944977,\n",
       "        0.01483578,  0.0111566 ,  0.01417956,  0.01050989,  0.00979975,\n",
       "        0.0097692 ,  0.02029282,  0.02144948,  0.01735042,  0.01967041,\n",
       "        0.02074549,  0.26224043,  0.1434906 ,  0.04881005])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = [0.14084561111646157, 0.49000480176388517, 0.098279597802745949, 0.87636718444262163, 0.77474887667917247, 1.9831920193301404, 1.8915968941565289, 0.85142737808334035, 0.60254578744891174, 1.7189738506990833, 1.7451472221296067, 0.39080231407369825, 0.14982792277025214, 0.53120426944312138, 0.83393535517405293, 0.5631421643406227, 0.27813108743646103, 0.51790169481522708, 0.21841686393752385, 0.14845677438018878, 0.14533496099354068, 0.87636718444262163, 0.93180053767449078, 0.71971704321339025, 0.84521581884656505, 0.89842921578915258, 3.435361850031839, 2.8323696648698924, 1.7540362888168379]\n",
    "softmax(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(softmax(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data \n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning strings\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip('\\n').strip().lower()\n",
    "\n",
    "def load_test_data(path, file_name):\n",
    "    df = pd.read_csv(path + file_name, sep='\\t', header=None)\n",
    "    df.columns = ['hardcoded_question', 'user_question']\n",
    "    for i in df.index:\n",
    "        df['hardcoded_question'][i] = clean_str(df['hardcoded_question'][i])\n",
    "        df['user_question'][i] = clean_str(df['user_question'][i])\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'data2/'\n",
    "file_name = 'test_set2.tsv'\n",
    "data = load_test_data(path, file_name)\n",
    "questions = data['hardcoded_question'].tolist() + data['user_question'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def embed_question(question):\n",
    "    question_tagged_nouns = filter_pos(question)\n",
    "    question_nouns = plural_to_singular(question_tagged_nouns)\n",
    "    embedding = np.zeros(model['random'].shape)\n",
    "    i=0.0\n",
    "    for word in question_nouns:\n",
    "        if word in model.vocab:\n",
    "            i+=1.0\n",
    "            embedding += model[word]\n",
    "    embedding /= i\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedded_questions = [embed_question(q) for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open ('data2/question_embeddings.tsv', 'w') as embeddings:\n",
    "    writer = csv.writer(embeddings, delimiter='\\t')\n",
    "    for eq in embedded_questions:\n",
    "        writer.writerow(eq)\n",
    "        \n",
    "with open ('data2/questions.tsv', 'w') as embeddings:\n",
    "    for q in questions:\n",
    "        embeddings.write(q+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
